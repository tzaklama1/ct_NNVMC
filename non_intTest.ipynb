{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422dc3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: submit63.mit.edu\n",
      "Python: /work/submit/tzaklama/ct_NNVMC/venvs/ct_nnvmc_venv/bin/python\n",
      "CUDA_VISIBLE_DEVICES: 0\n"
     ]
    }
   ],
   "source": [
    "import os, sys, platform, socket\n",
    "print(\"Host:\", socket.gethostname())\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.getenv(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a5a67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Host: submit63.mit.edu\n",
      "Python: /work/submit/tzaklama/ct_NNVMC/venvs/ct_nnvmc_venv/bin/python\n",
      "/dev/nvidia0  /dev/nvidia2  /dev/nvidiactl   /dev/nvidia-uvm-tools\n",
      "/dev/nvidia1  /dev/nvidia3  /dev/nvidia-uvm\n",
      "\n",
      "/dev/nvidia-caps:\n",
      "nvidia-cap1  nvidia-cap2\n",
      "GPU 0: NVIDIA GeForce GTX 1080 Ti (UUID: GPU-8cc96b65-f552-c8c5-ad52-03e6616b2931)\n"
     ]
    }
   ],
   "source": [
    "import os, socket, sys\n",
    "print(\"Host:\", socket.gethostname())      # MUST be c1234 (NOT submit66)\n",
    "print(\"Python:\", sys.executable)          # /work/.../ct_nnvmc_venv/bin/python\n",
    "!ls /dev/nvidia*                           # should list /dev/nvidia0, etc.\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2661ff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CudaDevice(id=0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or JAX\n",
    "import jax; jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f101f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_intTest.py\n",
    "\"\"\"\n",
    "Tests model for non-interacting 1d chain of fermions.\n",
    "\n",
    "1d non-int chain is calculated analytically for given configuration and then used as target for model.\n",
    "\"\"\"\n",
    "import jax, jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bbc824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate exact coefficients for non-interacting 1d chain of fermions\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def slater_coeffs_1d_sitebasis(L, N, bc=None):\n",
    "    \"\"\"Return (coeffs_complex, basis_masks) for the noninteracting ground state.\"\"\"\n",
    "    if bc is None:\n",
    "        bc = 'pbc' if (N % 2 == 1) else 'apbc'\n",
    "    phi = 0.0 if bc == 'pbc' else np.pi\n",
    "\n",
    "    # choose occupied momenta\n",
    "    if N % 2 == 0:\n",
    "        ns = np.arange(-N//2, N//2)\n",
    "    else:\n",
    "        ns = np.arange(-(N//2), N//2 + 1)\n",
    "    ks = (2*np.pi*ns + phi)/L\n",
    "\n",
    "    # all N-particle bitmasks (ascending order of positions)\n",
    "    from itertools import combinations\n",
    "    masks, positions = [], []\n",
    "    for occ in combinations(range(L), N):\n",
    "        masks.append(sum(1<<i for i in occ))\n",
    "        positions.append(np.array(occ, dtype=int))\n",
    "    positions = np.stack(positions)                          # (H, N)\n",
    "\n",
    "    # build orbital matrix Phi[a,x] = e^{ik_a x}/sqrt(L)\n",
    "    Phi = np.exp(1j*np.outer(ks, np.arange(L))) / np.sqrt(L) # (N, L)\n",
    "\n",
    "    # for each configuration, slice columns at positions and take det\n",
    "    coeffs = np.empty(len(masks), dtype=np.complex128)\n",
    "    for idx, pos in enumerate(positions):\n",
    "        coeffs[idx] = np.linalg.det(Phi[:, pos]) / np.sqrt(math.factorial(N))\n",
    "    return coeffs, np.array(masks, dtype=np.uint64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e024a74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/submit/tzaklama/ct_NNVMC\n",
      "Exact TB E0 = -4.82842712474619\n"
     ]
    }
   ],
   "source": [
    "## Calculate exact ground-state energy for non-interacting 1D chain of fermions for reference\n",
    "%cd /work/submit/tzaklama/ct_NNVMC\n",
    "import config as C\n",
    "def tb_E0_1d(L, N, t, bc=None):\n",
    "    \"\"\"\n",
    "    Exact ground-state energy for non-interacting 1D chain.\n",
    "    bc: 'pbc' or 'apbc' (auto-choose if None: pbc for odd N, apbc for even N)\n",
    "    \"\"\"\n",
    "    if bc is None:\n",
    "        bc = 'pbc' if (N % 2 == 1) else 'apbc'\n",
    "    phi = 0.0 if bc == 'pbc' else np.pi\n",
    "    # choose the N integers centered around 0\n",
    "    if N % 2 == 0:\n",
    "        ns = np.arange(-N//2, N//2)                # even N\n",
    "    else:\n",
    "        ns = np.arange(-(N//2), N//2 + 1)          # odd N\n",
    "    ks = (2*np.pi*ns + phi)/L\n",
    "    eps = -2*t*np.cos(ks)\n",
    "    return np.sum(np.sort(eps))  # already lowest; sort is harmless\n",
    "\n",
    "\n",
    "E_exact = tb_E0_1d(L=C.N_SITES, N=C.N_PART, t=2*C.T_HOP, bc='pbc')\n",
    "print(\"Exact TB E0 =\", E_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0356048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training states: 280 | Hamiltonians: 5\n",
      "JAX backend: GPU | lattice: 1d | N=8, Np=4\n",
      "epoch    0  loss = 5.4999e-01\n",
      "epoch  300  loss = 1.5936e-03\n",
      "epoch  600  loss = 8.5592e-06\n",
      "epoch  900  loss = 3.4672e-01\n",
      "epoch 1200  loss = 3.2688e-04\n",
      "epoch 1500  loss = 8.9407e-06\n",
      "epoch 1800  loss = 7.8678e-07\n",
      "epoch 2100  loss = 2.7895e-06\n",
      "epoch 2400  loss = 3.5763e-07\n",
      "epoch 2700  loss = 2.1458e-07\n",
      "epoch 3000  loss = 4.0531e-07\n",
      "epoch 3300  loss = 5.0068e-07\n",
      "\n",
      "First 10 coefficients for (t,V)=(0.5,0.0):\n",
      "|11000000⟩ → -3.91898 +2.09372 i\n",
      "|10100000⟩ → -3.92693 +6.84304 i\n",
      "|10010000⟩ → -2.45174 +8.18225 i\n",
      "|10001000⟩ → +1.58746 +11.37895 i\n",
      "|10000100⟩ → +7.04532 +6.03460 i\n",
      "|10000010⟩ → +5.42719 +5.38753 i\n",
      "|10000001⟩ → +4.42431 +3.73778 i\n",
      "|01100000⟩ → -0.74017 +5.49745 i\n",
      "|01010000⟩ → -0.79228 +7.10872 i\n",
      "|01001000⟩ → +4.48184 +5.99664 i\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Latest version of the code to train a Lattice-TransFormer on synthetic data for non-interacting fermions in 1D.\n",
    "\"\"\"\n",
    "import jax, jax.numpy as jnp, optax\n",
    "from flax.training import train_state\n",
    "import config as C\n",
    "T_LIST = [1.2, 1.0, 0.4, 0.6, 0.8]          # example\n",
    "V_LIST = [0.0, 0.0, 0.0, 0.0, 0.0]          # non-interacting, so V=0\n",
    "N_LIST = [2, 3, 5, 4, 4]          # particle numbers (can all differ)\n",
    "\n",
    "assert len(T_LIST)==len(V_LIST)==len(N_LIST)\n",
    "G = len(T_LIST)              # number of Hamiltonians\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2)  Build concatenated training set\n",
    "# ---------------------------------------------------------------------------\n",
    "OCC_ALL, LAM_ALL, TARGET_ALL, GID_ALL = [], [], [], []\n",
    "for gid,(t,v,npart) in enumerate(zip(T_LIST, V_LIST, N_LIST)):\n",
    "    # basis for this particle number --------------------\n",
    "    if C.LATTICE == \"1d\":\n",
    "        from phys_system.lattice1D import enumerate_fock, mask_to_array\n",
    "        basis = enumerate_fock(C.N_SITES, npart)\n",
    "        occ   = jnp.array([mask_to_array(m, C.N_SITES) for m in basis],\n",
    "                          dtype=jnp.int32)\n",
    "    else:\n",
    "        import phys_system.honeycomb as hc\n",
    "        basis = hc.enumerate_fock(C.N_SITES, npart)\n",
    "        occ   = jnp.array([hc.mask_to_array(m, C.N_SITES) for m in basis],\n",
    "                          dtype=jnp.int32)\n",
    "\n",
    "    # λ-vector extended to include N --------------------\n",
    "    lam_vec = jnp.array([t, v, npart], dtype=jnp.float32)\n",
    "    lam     = jnp.tile(lam_vec, (len(basis),1))\n",
    "\n",
    "    \n",
    "    # synthetic target coefficients replaced by exact non-interacting ones\n",
    "    #key  = jax.random.PRNGKey(C.SEED + gid)\n",
    "    #targ = jax.random.normal(key, (len(basis), 2))*0.1\n",
    "    coeffs, masks = slater_coeffs_1d_sitebasis(L=C.N_SITES, N=npart, bc='pbc')\n",
    "    # TARGET aligned to OCC (Re, Im)\n",
    "    targ = jnp.stack([jnp.array(coeffs.real), jnp.array(coeffs.imag)], axis=1)\n",
    "\n",
    "    gid_vec = jnp.full((len(basis),), gid, dtype=jnp.int32)\n",
    "\n",
    "    OCC_ALL.append(occ)\n",
    "    LAM_ALL.append(lam)\n",
    "    TARGET_ALL.append(targ)\n",
    "    GID_ALL.append(gid_vec)\n",
    "\n",
    "# concatenate everything --------------------------------\n",
    "OCC     = jnp.concatenate(OCC_ALL,    axis=0)\n",
    "LAM     = jnp.concatenate(LAM_ALL,    axis=0)   # shape (B,3)\n",
    "TARGET  = jnp.concatenate(TARGET_ALL, axis=0)\n",
    "GIDS    = jnp.concatenate(GID_ALL,    axis=0)   # shape (B,)\n",
    "\n",
    "print(\"Total training states:\", OCC.shape[0], \"| Hamiltonians:\", G)\n",
    "\n",
    "# ---------- model -----------------------------------------------------------\n",
    "from networks.model import LatticeTransFormer\n",
    "model = LatticeTransFormer(n_sites=C.N_SITES, depth=8, d_model=256)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3)  Loss & training step\n",
    "# ---------------------------------------------------------------------------\n",
    "from Loss.loss import overlap_loss_multi, amp_phase_loss, loss_normDiff   \n",
    "LOSS_TYPE = \"overlap_multi\"   # choose in config or set here\n",
    "\n",
    "def create_state(rng):\n",
    "    params = model.init(rng, OCC, LAM, train=False)\n",
    "    tx     = optax.adam(1e-3)\n",
    "    return train_state.TrainState.create(\n",
    "        apply_fn=model.apply, params=params, tx=tx)\n",
    "\n",
    "def loss_fn(params):\n",
    "    preds = model.apply(params, OCC, LAM, train=False)\n",
    "    if LOSS_TYPE == \"overlap_multi\":\n",
    "        return overlap_loss_multi(preds, TARGET, GIDS, num_groups=G)\n",
    "    elif LOSS_TYPE == \"amp_phase\":\n",
    "        return amp_phase_loss(preds, TARGET, neighbours)\n",
    "    elif LOSS_TYPE == \"original\":\n",
    "        return loss_normDiff(preds, TARGET)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown LOSS_TYPE\")\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state, loss\n",
    "\n",
    "# ---------- run -------------------------------------------------------------\n",
    "print(\"JAX backend:\", jax.default_backend().upper(),\n",
    "      \"| lattice:\", C.LATTICE,\n",
    "      f\"| N={C.N_SITES}, Np={C.N_PART}\")\n",
    "\n",
    "state = create_state(jax.random.PRNGKey(42))\n",
    "for epoch in range(3*C.EPOCHS):\n",
    "    state, loss = train_step(state)\n",
    "    if epoch % C.PRINT_EVERY == 0:\n",
    "        print(f\"epoch {epoch:4d}  loss = {float(loss):.4e}\")\n",
    "\n",
    "# ---------- output ----------------------------------------------------------\n",
    "coeffs = model.apply(state.params, OCC, LAM, train=False)\n",
    "print(f\"\\nFirst {C.N_PRINT} coefficients for (t,V)=({C.T_HOP},{0.0}):\")\n",
    "for i in range(min(C.N_PRINT, len(basis))):\n",
    "    n_str = ''.join(str(int(b)) for b in OCC[i])\n",
    "    re, im = map(float, coeffs[i])\n",
    "    print(f\"|{n_str}⟩ → {re:+.5f} {im:+.5f} i\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00292afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34ff6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Hamiltonian for the non-interacting 1D chain of fermions\n",
    "Array = jax.Array\n",
    "def H_builder(C) -> Array:\n",
    "    import itertools \n",
    "    from scipy.sparse import lil_matrix, csr_matrix \n",
    "    Ns              = C.N_SITES          # number of sites of the 1D chain\n",
    "    Nparticelle     = C.N_PART    # number of particles\n",
    "\n",
    "    # basis vectors  \n",
    "    klattice = 2*np.pi/Ns * np.arange(Ns)                                               # k lattice points  \n",
    "    linking_table = {jr: [np.mod(jr-1, Ns), np.mod(jr+1, Ns)] for jr in range(Ns)}      # 1D linking table \n",
    "    # generate Hilbert space \n",
    "    def n2occ(n,Nsize):\n",
    "        binr=np.binary_repr(n,width=Nsize) \n",
    "        return binr\n",
    "    def generate_combinations(N,Np):\n",
    "        \"\"\" Generate all combinations of Np particles from N available positions, returning them as binary numbers. \"\"\"\n",
    "        combinations = itertools.combinations(range(N), Np)\n",
    "        results = []\n",
    "        for comb in combinations:\n",
    "            binary_num = 0  # Start with an empty binary number (all zeros)\n",
    "            for i in comb:\n",
    "                binary_num |= (1 << i)  # Set the bit at position i\n",
    "            results.append(binary_num)  # Append the binary number to the results\n",
    "        return results\n",
    "    ##### Nparticelle number of particles specified previously >> N=2*Ns \n",
    "    combinations = generate_combinations(N=Ns,Np=Nparticelle)\n",
    "    Nstates = len(combinations)\n",
    "    states = np.arange(Nstates)\n",
    "    state2ind = dict(zip(combinations,states))\n",
    "    print(\"Number of states =\",Nstates)  \n",
    "    ###### hopping \n",
    "    def hop(string,j1,j2): # hopping \n",
    "        Ncount = sum( int(string[j]) for j in range(j2) ) + sum( int(string[j]) for j in range(j1) )  \n",
    "        if j2 >= j1: \n",
    "            hop_sign = Ncount\n",
    "        else: \n",
    "            hop_sign = 1 + Ncount \n",
    "        # distruggo in j2 \n",
    "        tmp = string \n",
    "        tmp = \"o\"+tmp+\"o\" \n",
    "        tmp = tmp[:1+j2]+\"0\"+tmp[2+j2:] \n",
    "        tmp_p = tmp[1:-1] \n",
    "        # creo in j1 \n",
    "        tmp_p = \"o\"+tmp_p+\"o\" \n",
    "        tmp_p = tmp_p[:1+j1]+\"1\"+tmp_p[2+j1:]  \n",
    "        out = tmp_p[1:-1]\n",
    "        return out, (-1)**hop_sign\n",
    "    # Build the Hamiltonian\n",
    "    Htunnel = lil_matrix((Nstates, Nstates), dtype=np.float64)   # LIL format for easy assignment\n",
    "    #Hint    = lil_matrix((Nstates, Nstates), dtype=np.float64)   # LIL format for easy assignment \n",
    "    #Hloc    = lil_matrix((Nstates, Nstates), dtype=np.float64)   # LIL format for easy assignment\n",
    "    for key, index in state2ind.items():\n",
    "        string = n2occ(n=key,Nsize=Ns)  \n",
    "        occ_vals = np.array([int(bit) for bit in string])  \n",
    "        posAH = np.where(occ_vals == 1)[0]\n",
    "        #posAH_odd = posAH[posAH % 2 == 1]\n",
    "        #Hloc[index,index] = len(posAH_odd)  # number of odd particles in the state \n",
    "        for xx in posAH: \n",
    "            jxx = linking_table[xx]\n",
    "            #Pxx = [ occ_vals[j] for j in jxx]\n",
    "            # print( xx , f'linking table, {jxx}', f'Pxx {Pxx}' , string , Pxx.count(1) )\n",
    "            #Hint[index,index] += Pxx.count(1)/2 \n",
    "            for yy in jxx:  \n",
    "                if occ_vals[yy] == 0: \n",
    "                    string_new, segno = hop(string=string,j1=yy,j2=xx)\n",
    "                    # print( xx , yy , f'new string {string_new}, sign {segno}' )\n",
    "                    occ_new = np.array([int(bit) for bit in string_new])  \n",
    "                    key_new = int(string_new,2) \n",
    "                    index_new = state2ind[key_new] \n",
    "                    Htunnel[index_new,index] += -segno\n",
    "    # Convert LIL matrix to dense numpy array, then to jax array\n",
    "    H_dense = np.array(Htunnel.todense(), dtype=np.float32)\n",
    "    H_jax = jnp.array(H_dense)\n",
    "    return H_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bec997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler_jax.py\n",
    "\"\"\"\n",
    "Metropolis–Hastings sampler for spinless fermion Fock states at fixed N.\n",
    "Targets p(σ) ∝ |ψ(σ; λ)|^2 using your trained JAX model.\n",
    "\n",
    "API:\n",
    "  occ_batch = sample_occ_batch(\n",
    "      model_apply, params, lam_vec, L, N,\n",
    "      num_samples=4096, burn_in=1024, thin=4, n_chains=16, rng_seed=0)\n",
    "\n",
    "where\n",
    "  • model_apply(params, occ, lam, train=False) -> (B, 2) [Re, Im]\n",
    "  • lam_vec is a 1D array, e.g. [t, V, N]  or  [t, V]\n",
    "  • returns occ_batch as int32 array of shape (num_samples, L)\n",
    "\"\"\"\n",
    "\n",
    "from typing import Callable, Tuple\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "# ------------------------- utilities ----------------------------------------\n",
    "def _random_occ(L: int, N: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Random bitstring with exactly N ones among L sites.\"\"\"\n",
    "    occ = np.zeros(L, dtype=np.int8)\n",
    "    occ[rng.choice(L, size=N, replace=False)] = 1\n",
    "    return occ\n",
    "\n",
    "def _propose_exchange(occ: np.ndarray, rng: np.random.Generator) -> Tuple[np.ndarray, int, int]:\n",
    "    \"\"\"\n",
    "    Propose a number-conserving move: pick one occupied site i and one empty site j and swap.\n",
    "    Returns (new_occ, i, j).  If all 0s or 1s (should not happen), returns copy.\n",
    "    \"\"\"\n",
    "    ones  = np.flatnonzero(occ == 1)\n",
    "    zeros = np.flatnonzero(occ == 0)\n",
    "    if len(ones) == 0 or len(zeros) == 0:\n",
    "        return occ.copy(), -1, -1\n",
    "    i = int(rng.choice(ones))\n",
    "    j = int(rng.choice(zeros))\n",
    "    new_occ = occ.copy()\n",
    "    new_occ[i] = 0\n",
    "    new_occ[j] = 1\n",
    "    return new_occ, i, j\n",
    "\n",
    "@jax.jit\n",
    "def _coeffs_to_probs(coeff_ri: jnp.ndarray) -> jnp.ndarray:\n",
    "    \"\"\"(B,2)->(B,) probabilities |ψ|^2 with small epsilon for stability.\"\"\"\n",
    "    psi = coeff_ri[:, 0] + 1j * coeff_ri[:, 1]\n",
    "    return (jnp.abs(psi) ** 2 + 1e-30).real\n",
    "\n",
    "def _eval_probs(model_apply, params, occ_batch: np.ndarray, lam_vec: jnp.ndarray) -> np.ndarray:\n",
    "    \"\"\"Evaluate |ψ|^2 for a batch of integer 0/1 arrays (np) at fixed λ.\"\"\"\n",
    "    occ_j = jnp.asarray(occ_batch, dtype=jnp.int32)\n",
    "    lam_b = jnp.tile(lam_vec[None, :], (occ_j.shape[0], 1))\n",
    "    coeff = model_apply(params, occ_j, lam_b, train=False)        # (B,2)\n",
    "    probs = _coeffs_to_probs(coeff)                               # (B,)\n",
    "    # IMPORTANT: return a WRITEABLE NumPy array\n",
    "    return np.array(probs, dtype=np.float64, copy=True)\n",
    "\n",
    "\n",
    "# ------------------------- main sampler -------------------------------------\n",
    "def sample_occ_batch(model_apply: Callable,\n",
    "                     params,\n",
    "                     lam_vec: jnp.ndarray,\n",
    "                     L: int,\n",
    "                     N: int,\n",
    "                     num_samples: int = 4096,\n",
    "                     burn_in: int = 1024,\n",
    "                     thin: int = 4,\n",
    "                     n_chains: int = 16,\n",
    "                     rng_seed: int = 0) -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Return an array of shape (num_samples, L) with entries in {0,1},\n",
    "    distributed approximately as |ψ(σ;λ)|^2, using n_chains independent MH chains.\n",
    "    \"\"\"\n",
    "    assert 0 <= N <= L\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "\n",
    "    # allocate per-chain state\n",
    "    chains = np.stack([_random_occ(L, N, rng) for _ in range(n_chains)], axis=0)  # (C, L)\n",
    "    probs  = _eval_probs(model_apply, params, chains, lam_vec)                    # (C,)\n",
    "    if not probs.flags.writeable:\n",
    "        probs = probs.copy()\n",
    "\n",
    "    # how many samples per chain (ceil)\n",
    "    per_chain = (num_samples + n_chains - 1) // n_chains\n",
    "    samples = []\n",
    "\n",
    "    total_steps = burn_in + thin * per_chain\n",
    "    for step in range(total_steps):\n",
    "        # Propose for all chains in parallel (Python level)\n",
    "        props = []\n",
    "        for c in range(n_chains):\n",
    "            occ_new, _, _ = _propose_exchange(chains[c], rng)\n",
    "            props.append(occ_new)\n",
    "        props = np.stack(props, axis=0)                                # (C, L)\n",
    "\n",
    "        probs_new = _eval_probs(model_apply, params, props, lam_vec)   # (C,)\n",
    "        # MH accept\n",
    "        accept_ratio = probs_new / (probs + 1e-300)\n",
    "        accept = rng.random(n_chains) < np.minimum(1.0, accept_ratio)\n",
    "\n",
    "        # update chains & probs\n",
    "        chains[accept] = props[accept]\n",
    "        probs[accept]  = probs_new[accept]\n",
    "\n",
    "        # record (after burn-in) with thinning\n",
    "        if step >= burn_in and ((step - burn_in) % thin == 0):\n",
    "            samples.append(chains.copy())\n",
    "\n",
    "    # collect & trim\n",
    "    if len(samples) == 0:\n",
    "        # edge case: too small total_steps\n",
    "        return jnp.asarray(chains[:num_samples], dtype=jnp.int32)\n",
    "\n",
    "    samples = np.concatenate(samples, axis=0)           # (~per_chain, C, L)\n",
    "    samples = samples.reshape(-1, L)                    # (C*~, L)\n",
    "    samples = samples[:num_samples]                     # exact M\n",
    "    return jnp.asarray(samples, dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3f7094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states = 70\n"
     ]
    }
   ],
   "source": [
    "## Given ground state wavefunction, what is ground state energy?\n",
    "import observables.energy as E\n",
    "import sampler.sampler_jax as sampler\n",
    "# (Assumes you have (i) a sampler that draws σ ~ |ψ|^2 and (ii) H for the basis.)\n",
    "\n",
    "model_apply = lambda params, occ, lam, train=False: \\\n",
    "    model.apply(params, occ, lam, train=train)\n",
    "\n",
    "L, N, t = C.N_SITES, C.N_PART, C.T_HOP\n",
    "\n",
    "# 1) Basis + index map (must match H ordering!) (For ED and beyond)\n",
    "basis_masks = enumerate_fock(L, N)\n",
    "occ_basis   = jnp.array([mask_to_array(m, L) for m in basis_masks], dtype=jnp.int32)\n",
    "state_index = E.build_state_index([int(m) for m in basis_masks])\n",
    "\n",
    "# 2) Hamiltonian for appropriate basis\n",
    "H = H_builder(C) # can change this but currently C is set to npart = 4 and L = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "511ab997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0(model, MC) = -4.266851902008057\n"
     ]
    }
   ],
   "source": [
    "# 3) Draw M samples σ ~ |ψ|^2  (use your sampler; pseudo-code shown)\n",
    "M = 1024\n",
    "lam_vec   = jnp.array([2*t, 0.0, float(N)], dtype=jnp.float32) # non-interacting, so V=0 # C.T_HOP is 0.5\n",
    "lam_batch = jnp.tile(lam_vec, (M, 1))\n",
    "\n",
    "# 1) Draw configurations σ ~ |ψ|^2\n",
    "occ_batch = sample_occ_batch(model_apply, state.params, lam_vec,\n",
    "                             L=L, N=N,\n",
    "                             num_samples=M, burn_in=256, thin=4,\n",
    "                             n_chains=32, rng_seed=0)\n",
    "\n",
    "def model_fn(occ, lam):\n",
    "    coeff = model_apply(state.params, occ, lam, train=False)  # (B,2)\n",
    "    return (coeff[:, 0] + 1j * coeff[:, 1]).astype(jnp.complex64)\n",
    "\n",
    "# 4) Monte Carlo energy (module function averages local energies)\n",
    "E_mc = E.expectation_local_energy(model=model_fn,\n",
    "                      occ_batch=occ_batch,\n",
    "                      params_batch=lam_batch,\n",
    "                      H=H,\n",
    "                      occ_basis=occ_basis,\n",
    "                      state_index=state_index)\n",
    "print(\"E0(model, MC) =\", float(E_mc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc7ba273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0(model, MC) = -4.828277587890625\n"
     ]
    }
   ],
   "source": [
    "# Larger M for better accuracy, takes far longer and is marginally better\n",
    "M = 4096\n",
    "lam_vec   = jnp.array([t, 0.0, float(N)], dtype=jnp.float32) # non-interacting, so V=0\n",
    "lam_batch = jnp.tile(lam_vec, (M, 1))\n",
    "\n",
    "# 1) Draw configurations σ ~ |ψ|^2\n",
    "occ_batch = sample_occ_batch(model_apply, state.params, lam_vec,\n",
    "                             L=L, N=N,\n",
    "                             num_samples=M, burn_in=1024, thin=4,\n",
    "                             n_chains=32, rng_seed=0)\n",
    "\n",
    "def model_fn(occ, lam):\n",
    "    coeff = model_apply(state.params, occ, lam, train=False)  # (B,2)\n",
    "    return (coeff[:, 0] + 1j * coeff[:, 1]).astype(jnp.complex64)\n",
    "\n",
    "# 4) Monte Carlo energy (module function averages local energies)\n",
    "E_mc = E.expectation_local_energy(model=model_fn,\n",
    "                      occ_batch=occ_batch,\n",
    "                      params_batch=lam_batch,\n",
    "                      H=H,\n",
    "                      occ_basis=occ_basis,\n",
    "                      state_index=state_index)\n",
    "print(\"E0(model, MC) =\", float(E_mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b4c3862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0(H) = -4.828428745269775\n"
     ]
    }
   ],
   "source": [
    "# use the SAME H you pass to expectation_local_energy (straight exact diagonalization)\n",
    "evals = jnp.linalg.eigvalsh(H)      # H is (Hdim,Hdim) in N-sector\n",
    "E_exact_from_H = float(evals[0])\n",
    "print(\"E0(H) =\", E_exact_from_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6448d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0(Rayleigh) = -3.919802665710449\n"
     ]
    }
   ],
   "source": [
    "# Rayleigh quotient method\n",
    "# psi_full on the full basis used to build H\n",
    "psi   = model_fn(occ, lam)\n",
    "E_ray = float((jnp.vdot(psi, H @ psi) / (jnp.vdot(psi, psi) + 1e-12)).real) ## Hilbert space needs to be same for model and H\n",
    "# Throws error because model is npart = 3 and L = 8 while H is npart = 4 and L = 8\n",
    "print(\"E0(Rayleigh) =\", E_ray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b93592d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0(model, MC) = -3.914226531982422\n"
     ]
    }
   ],
   "source": [
    "E_mc = float(E.expectation_local_energy(\n",
    "              model=model_fn, occ_batch=occ_batch,\n",
    "              params_batch=lam_batch, H=H,\n",
    "              occ_basis=occ_basis, state_index=state_index).real)\n",
    "print(\"E0(model, MC) =\", E_mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e70d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E0(model, local energy) = -1.9571131467819214\n"
     ]
    }
   ],
   "source": [
    "# local_energy_1d.py  (drop-in helper)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def local_energy_1d_tb(model_fn, occ_batch: jnp.ndarray, lam_batch: jnp.ndarray,\n",
    "                       t: float, bc: str = \"pbc\") -> jnp.ndarray:\n",
    "    M, L = occ_batch.shape\n",
    "    N = jnp.sum(occ_batch[0])  # fixed-N sampler\n",
    "    # base amplitudes\n",
    "    psi = model_fn(occ_batch, lam_batch)  # (M,)\n",
    "    eps = 1e-30\n",
    "\n",
    "    # helper to flip i->j\n",
    "    def move(occ_np, i, j):\n",
    "        occ2 = occ_np.copy()\n",
    "        occ2[i] = 0; occ2[j] = 1\n",
    "        return occ2\n",
    "\n",
    "    # JW sign for wrap hops:\n",
    "    jw = 1.0 if (int(N) % 2 == 1) else -1.0\n",
    "    bc_phase = 1.0 if bc == \"pbc\" else -1.0  # add a twist if you want APBC\n",
    "    wrap_sign = jw * bc_phase\n",
    "\n",
    "    E_loc = np.zeros(M, dtype=np.complex64)\n",
    "\n",
    "    # loop in Python (clear & reliable; vectorise later if needed)\n",
    "    for m in range(M):\n",
    "        occ = np.asarray(occ_batch[m])\n",
    "        lam = np.asarray(lam_batch[m])\n",
    "        denom = complex(psi[m])\n",
    "        if abs(denom) < eps:\n",
    "            continue\n",
    "        acc = 0.0 + 0.0j\n",
    "        for i in range(L):\n",
    "            if occ[i] == 0: \n",
    "                continue\n",
    "            # hop right\n",
    "            j = (i + 1) % L\n",
    "            if occ[j] == 0:\n",
    "                occ2 = move(occ, i, j)\n",
    "                # wrap sign if i->j crosses boundary\n",
    "                sgn = wrap_sign if (i == L-1 and j == 0) else 1.0\n",
    "                num = complex(model_fn(jnp.asarray(occ2[None,:], dtype=jnp.int32),\n",
    "                                       jnp.asarray(lam[None,:], dtype=jnp.float32))[0])\n",
    "                acc += -t * sgn * (num / denom)\n",
    "            # hop left\n",
    "            j = (i - 1) % L\n",
    "            if occ[j] == 0:\n",
    "                occ2 = move(occ, i, j)\n",
    "                sgn = wrap_sign if (i == 0 and j == L-1) else 1.0\n",
    "                num = complex(model_fn(jnp.asarray(occ2[None,:], dtype=jnp.int32),\n",
    "                                       jnp.asarray(lam[None,:], dtype=jnp.float32))[0])\n",
    "                acc += -t * sgn * (num / denom)\n",
    "        E_loc[m] = acc\n",
    "    return jnp.asarray(E_loc)\n",
    "\n",
    "E_loc = local_energy_1d_tb(model_fn, occ_batch, lam_batch, C.T_HOP, bc=\"pbc\")\n",
    "E_mc  = float(jnp.mean(E_loc).real)\n",
    "print(\"E0(model, local energy) =\", E_mc) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e8c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states = 56\n",
      "E0(H) = -4.828426837921143\n"
     ]
    }
   ],
   "source": [
    "## Old version sketch of how to get local energy \n",
    "\"\"\" ## Given ground state wavefunction, what is ground state energy?\n",
    "import observables.energy as E\n",
    "import sampler.mcmc as sampler\n",
    "# (Assumes you have (i) a sampler that draws σ ~ |ψ|^2 and (ii) H for the basis.)\n",
    "\n",
    "model_apply = lambda params, occ, lam, train=False: \\\n",
    "    model.apply(params, occ, lam, train=train)\n",
    "\n",
    "# 1) Basis + index map (must match H ordering!)\n",
    "basis_masks = enumerate_fock(C.N_SITES, C.N_PART)\n",
    "occ_basis   = jnp.array([mask_to_array(m, C.N_SITES) for m in basis_masks], dtype=jnp.int32)\n",
    "state_index = E.build_state_index([int(m) for m in basis_masks])\n",
    "\n",
    "# 2) Your Hamiltonian for that basis\n",
    "# H = your_ed_builder(...)\n",
    "\n",
    "# 3) Draw M samples σ ~ |ψ|^2  (use your sampler; pseudo-code shown)\n",
    "M = 4096\n",
    "lam_vec   = jnp.array([C.T_HOP, 0.0, C.N_PART], dtype=jnp.float32) # non-interacting, so V=0\n",
    "lam_batch = jnp.tile(lam_vec, (M, 1))\n",
    "# occ_batch = sampler.sample(model, state.params, lam_vec, M)  # shape (M, N_sites)\n",
    "occ_batch = sampler.sample_chain(init_state: Array,\n",
    "                 log_prob_fn: model_apply,\n",
    "                 key: PRNGKey,\n",
    "                 n_samples: 4096,\n",
    "                 burn_in= 100,\n",
    "                 thin=1)\n",
    "\n",
    "# 4) Monte Carlo energy (module function averages local energies)\n",
    "E_mc = E.expectation_local_energy(model=model_apply,\n",
    "                      occ_batch=occ_batch,\n",
    "                      params_batch=lam_batch,\n",
    "                      H=H,\n",
    "                      occ_basis=occ_basis,\n",
    "                      state_index=state_index)\n",
    "print(\"E0(model, MC) =\", float(E_mc)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1de63c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ct_nnvmc @ GPU)",
   "language": "python",
   "name": "ct_nnvmmc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
